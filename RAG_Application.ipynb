{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WZp8J48mB68"
      },
      "source": [
        "# ðŸ“˜ RAG Application (DMP Example) using LangChain + **Local Llama (Ollama)** + FAISS\n",
        "\n",
        "This notebook is the same practical RAG tutorial, but **without OpenAI**.\n",
        "\n",
        "âœ… We use:\n",
        "- **Ollama** to run a local Llama model for generation (e.g., `llama3.2`, `llama3.1`, etc.)\n",
        "- **Ollama embeddings** for vector search (e.g., `nomic-embed-text` or `mxbai-embed-large`)\n",
        "- **FAISS** as the vector store\n",
        "\n",
        "You will:\n",
        "1. Create a small DMP guidance file (`dmp_guidance.txt`)\n",
        "2. Load it\n",
        "3. Chunk it\n",
        "4. Embed + index with FAISS\n",
        "5. Build:\n",
        "   - **Baseline (no RAG)**\n",
        "   - **RAG (retrieve + grounded answer)**\n",
        "6. Compare results for the same DMP question\n",
        "\n",
        "---\n",
        "## ðŸ”´ Important\n",
        "You must have **Ollama installed and running** on your machine.\n",
        "\n",
        "- Install Ollama: https://ollama.com\n",
        "- Then pull models from the terminal (or from notebook cells below):\n",
        "  - `ollama pull llama3.2`\n",
        "  - `ollama pull nomic-embed-text`  *(embedding model)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-fUCj0KmJGX"
      },
      "source": [
        "## ðŸ”§ 1) Install Python dependencies (run once)\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ¦™ 2) Make sure Ollama is installed + pull models\n",
        "\n",
        "Run these in your terminal **once** (recommended):\n",
        "```bash\n",
        "ollama pull llama3.2\n",
        "ollama pull nomic-embed-text\n",
        "```\n",
        "\n",
        "Or you can try running the commands below from the notebook.  \n",
        "(If your environment doesn't allow shell commands, do it in the terminal.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jmGu5Lr-mPZG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Ollama models configured: llama3.2 | nomic-embed-text\n"
          ]
        }
      ],
      "source": [
        "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "\n",
        "# --- Choose models you have pulled via `ollama pull ...`\n",
        "LLM_MODEL = \"llama3.2\"            # generation model\n",
        "EMBED_MODEL = \"nomic-embed-text\"  # embeddings model (recommended)\n",
        "\n",
        "# Initialize Ollama chat model\n",
        "llm = ChatOllama(model=LLM_MODEL, temperature=0.2)\n",
        "\n",
        "# Initialize Ollama embeddings model\n",
        "embeddings = OllamaEmbeddings(model=EMBED_MODEL)\n",
        "\n",
        "print(\"âœ… Ollama models configured:\", LLM_MODEL, \"|\", EMBED_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYPoOcMVutNQ"
      },
      "source": [
        "## ðŸ“„ 3) Create a practical DMP guidance document\n",
        "\n",
        "For a blog/tutorial example, we create a small text file containing NIH DMS plan requirements and common guidance.\n",
        "In production, you would replace this with:\n",
        "- NIH policy pages (HTML/PDF)\n",
        "- DMPTool guidance text\n",
        "- Institutional sharing policy text\n",
        "- Repository documentation\n",
        "\n",
        "The key idea: **RAG retrieves from these sources** instead of the LLM guessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Created file: dmp_guidance.txt\n"
          ]
        }
      ],
      "source": [
        "guidance_text = \"\"\"\n",
        "NIH DMS Plan Required Elements:\n",
        "A Data Management and Sharing (DMS) Plan should address:\n",
        "(1) Data type and amount\n",
        "(2) Related tools, software, and documentation\n",
        "(3) Standards\n",
        "(4) Repository selection\n",
        "(5) Timing of sharing\n",
        "(6) Access, distribution, or reuse considerations\n",
        "\n",
        "Repository selection guidance:\n",
        "Repository selection should be justified by data type and community norms.\n",
        "The repository should support metadata, persistent identifiers, long-term preservation,\n",
        "and (when needed) access controls for sensitive data.\n",
        "\n",
        "Human participant data & controlled access:\n",
        "For human participant data, sharing may require controlled access and safeguards.\n",
        "Plans should describe de-identification steps, governance (e.g., Data Use Agreements),\n",
        "and an access review/approval process.\n",
        "\n",
        "Documentation & metadata:\n",
        "Documentation should support reuse: README, data dictionary/codebook, variable definitions,\n",
        "provenance notes, and metadata needed for discovery and interpretation.\n",
        "\n",
        "Timing of sharing:\n",
        "Timing should specify when data will be shared (e.g., at publication, end of project,\n",
        "or rolling releases). Any embargo/delay should be justified by ethics or policy.\n",
        "\n",
        "Derived data when raw data cannot be shared:\n",
        "If raw patient-level data cannot be shared broadly, plans can share derived or aggregated outputs\n",
        "(e.g., feature tables, summary statistics, model performance metrics) to maximize reuse while protecting privacy.\n",
        "\"\"\".strip()\n",
        "\n",
        "with open(\"dmp_guidance.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(guidance_text)\n",
        "\n",
        "print(\"âœ… Created file: dmp_guidance.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¥ 4) Load the document using LangChain\n",
        "\n",
        "LangChain represents documents as `Document` objects with:\n",
        "- `page_content` (text)\n",
        "- `metadata` (optional)\n",
        "\n",
        "Weâ€™ll use `TextLoader` for this demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded documents: 1\n",
            "\n",
            "--- Preview (first 600 chars) ---\n",
            "\n",
            "NIH DMS Plan Required Elements:\n",
            "A Data Management and Sharing (DMS) Plan should address:\n",
            "(1) Data type and amount\n",
            "(2) Related tools, software, and documentation\n",
            "(3) Standards\n",
            "(4) Repository selection\n",
            "(5) Timing of sharing\n",
            "(6) Access, distribution, or reuse considerations\n",
            "\n",
            "Repository selection guidance:\n",
            "Repository selection should be justified by data type and community norms.\n",
            "The repository should support metadata, persistent identifiers, long-term preservation,\n",
            "and (when needed) access controls for sensitive data.\n",
            "\n",
            "Human participant data & controlled access:\n",
            "For human participant data, sharin...\n"
          ]
        }
      ],
      "source": [
        "loader = TextLoader(\"dmp_guidance.txt\", encoding=\"utf-8\")\n",
        "documents = loader.load()\n",
        "\n",
        "print(\"Loaded documents:\", len(documents))\n",
        "print(\"\\n--- Preview (first 600 chars) ---\\n\")\n",
        "print(documents[0].page_content[:600] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ‚ï¸ 5) Chunk the text\n",
        "\n",
        "Why chunk?\n",
        "- Embeddings work best on moderate-size text segments\n",
        "- Retrieval becomes more precise\n",
        "\n",
        "We use `RecursiveCharacterTextSplitter` to chunk with overlap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chunks: 4\n",
            "\n",
            "--- Example chunk ---\n",
            "\n",
            "NIH DMS Plan Required Elements:\n",
            "A Data Management and Sharing (DMS) Plan should address:\n",
            "(1) Data type and amount\n",
            "(2) Related tools, software, and documentation\n",
            "(3) Standards\n",
            "(4) Repository selection\n",
            "(5) Timing of sharing\n",
            "(6) Access, distribution, or reuse considerations\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=450,\n",
        "    chunk_overlap=60\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(\"Total chunks:\", len(chunks))\n",
        "print(\"\\n--- Example chunk ---\\n\")\n",
        "print(chunks[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ” 6) Build FAISS vector store + retriever (with Ollama embeddings)\n",
        "\n",
        "- Embed each chunk\n",
        "- Store in FAISS\n",
        "- Create retriever (`k=4`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Vectorstore ready (FAISS). Retriever k=4\n"
          ]
        }
      ],
      "source": [
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "print(\"âœ… Vectorstore ready (FAISS). Retriever k=4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ§  8) Build Baseline vs RAG pipelines (no OpenAI)\n",
        "\n",
        "Weâ€™ll do it in a simple, explicit way (easy to understand for a blog post).\n",
        "\n",
        "### Baseline (no RAG)\n",
        "- Just ask the Llama model directly\n",
        "\n",
        "### RAG\n",
        "- Retrieve top-k relevant chunks\n",
        "- Inject them into the prompt\n",
        "- Ask model to cite chunk IDs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Functions ready: answer_without_rag(), answer_with_rag()\n"
          ]
        }
      ],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([f\"[Chunk {i}] {d.page_content}\" for i, d in enumerate(docs)])\n",
        "\n",
        "def answer_without_rag(question: str) -> str:\n",
        "    prompt = f\"\"\"You are helping write an NIH Data Management and Sharing Plan.\n",
        "Answer the question using only your general knowledge.\n",
        "Be concise and structured.\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "    return llm.invoke(prompt).content\n",
        "\n",
        "def answer_with_rag(question: str) -> str:\n",
        "    retrieved = retriever.invoke(question)\n",
        "    context = format_docs(retrieved)\n",
        "\n",
        "    prompt = f\"\"\"You are helping write an NIH Data Management and Sharing Plan.\n",
        "\n",
        "Use ONLY the retrieved context to answer. If the context is insufficient, say what is missing.\n",
        "Keep it practical and aligned with NIH DMS Plan language.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Retrieved Context:\n",
        "{context}\n",
        "\n",
        "Answer format:\n",
        "- Repository selection\n",
        "- Timing of sharing\n",
        "- Access / distribution / reuse\n",
        "- Documentation & metadata\n",
        "- Citations: (list chunk ids you relied on)\n",
        "\"\"\"\n",
        "    return llm.invoke(prompt).content\n",
        "\n",
        "print(\"âœ… Functions ready: answer_without_rag(), answer_with_rag()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… 9) Run the same question: WITHOUT RAG vs WITH RAG\n",
        "\n",
        "This question matches our DMP-Chef style:\n",
        "- human subjects\n",
        "- restricted raw sharing\n",
        "- need repository + timing + access controls language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================== WITHOUT RAG ======================\n",
            "Here's a suggested outline for the NIH Data Management and Sharing (DMS) Plan:\n",
            "\n",
            "I. Repository Selection\n",
            "\n",
            "* Describe the de-identified EHR notes and CT imaging data repositories used to store and manage the data.\n",
            "* Explain how the data will be stored in accordance with HIPAA regulations, such as using secure, encrypted, and auditable storage solutions.\n",
            "\n",
            "II. Timing of Sharing\n",
            "\n",
            "* Specify that raw patient-level data will not be shared broadly, but de-identified data may be shared through approved channels (e.g., Data & Knowledge Network).\n",
            "* Describe the timeline for sharing de-identified data, including any milestones or deadlines.\n",
            "* Explain how access to shared data will be restricted to authorized personnel and institutions.\n",
            "\n",
            "III. Access Controls\n",
            "\n",
            "* Outline the measures taken to ensure secure access to shared data, such as:\n",
            " + User authentication and authorization\n",
            " + Role-based access controls\n",
            " + Data encryption and anonymization\n",
            " + Auditing and monitoring of access requests\n",
            "* Describe how data sharing agreements (DSAs) will be used to govern access to shared data.\n",
            "\n",
            "Example:\n",
            "\n",
            "\"Our project uses de-identified EHR notes and CT imaging stored in a secure, HIPAA-compliant repository. We will not share raw patient-level data broadly but may share de-identified data through approved channels, such as the Data & Knowledge Network. Access to shared data will be restricted to authorized personnel and institutions using user authentication, role-based access controls, and data encryption. Data sharing agreements (DSAs) will govern access to shared data.\"\n",
            "\n",
            "======================== WITH RAG ========================\n",
            "Based on the retrieved context, here are the answers:\n",
            "\n",
            "- Repository selection: The repository should be selected based on data type and community norms. It should support metadata, persistent identifiers, long-term preservation, and access controls for sensitive data.\n",
            "\n",
            "- Timing of sharing: Derived data can be shared when raw patient-level data cannot be shared broadly. Sharing will occur at publication or end of project, with any embargo/delay justified by ethics or policy.\n",
            "\n",
            "- Access / distribution / reuse: Controlled access may be required for human participant data. The plan should describe de-identification steps, governance (e.g., Data Use Agreements), and an access review/approval process. Derived outputs can be shared to maximize reuse while protecting privacy.\n",
            "\n",
            "- Documentation & metadata: Documentation should support reuse with a README, data dictionary/codebook, variable definitions, provenance notes, and metadata needed for discovery and interpretation.\n",
            "\n",
            "Citations:\n",
            "- [Chunk 1]\n",
            "- [Chunk 2]\n",
            "- [Chunk 3]\n"
          ]
        }
      ],
      "source": [
        "question = (\n",
        "    \"Our project uses de-identified EHR notes and CT imaging. We will not share raw patient-level data broadly. \" \n",
        "    \"What should we write in the NIH DMS Plan about repository selection, timing of sharing, and access controls?\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*22 + \" WITHOUT RAG \" + \"=\"*22)\n",
        "print(answer_without_rag(question))\n",
        "\n",
        "print(\"\\n\" + \"=\"*24 + \" WITH RAG \" + \"=\"*24)\n",
        "print(answer_with_rag(question))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes (practical tips)\n",
        "\n",
        "- **Embeddings model matters**: `nomic-embed-text` and `mxbai-embed-large` are common choices in Ollama.\n",
        "- **Llama is for generation**, not embeddings. Use a dedicated embedding model for retrieval.\n",
        "- If your model is slow on CPU, try a smaller Llama variant (e.g., `llama3.2:3b` if available in the Ollama library)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
